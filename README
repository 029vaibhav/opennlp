Introduction
============
The opennlp project is now the home of a set of java-based NLP tools 
which perform sentence detection, tokenization, pos-tagging, chunking and
parsing, and named-entity detection.  

In its previous life it was used to hold a common infrastructure code
for the opennlp.grok project.  The work previously done can be found in
the final release of that project available on the main project page.

Installing the build tools
==========================

The OpenNLP build system is based on Jakarta Ant, which is a Java
building tool originally developed for the Jakarta Tomcat project but
now used in many other Apache projects and extended by many
developers.

Ant is a little but very handy tool that uses a build file written in
XML (build.xml) as building instructions. For more information refer
to "http://jakarta.apache.org/ant/".

The only thing that you have to make sure of is that the "JAVA_HOME"
environment property is set to match the top level directory
containing the JVM you want to use. For example:

C:\> set JAVA_HOME=C:\jdk1.2.2

or on Unix:

% setenv JAVA_HOME /usr/local/java
  (csh)
> JAVA_HOME=/usr/java; export JAVA_HOME
  (ksh, bash)

That's it!


Building instructions
=====================

Ok, let's build the code. First, make sure your current working
directory is where the build.xml file is located. Then type

  ./build.sh (unix)

if everything is right and all the required packages are visible, this
action will generate a file called "opennlp-common-${version}.jar" in
the "./build" directory. Note, that if you do further development,
compilation time is reduced since Ant is able to detect which files
have changed an to recompile them at need.

Also, you'll note that reusing a single JVM instance for each task, increases
tremendously the performance of the whole build system, compared to other
tools (i.e. make or shell scripts) where a new JVM is started for each task.


Build targets
=============

The build system is not only responsible for compiling Opennlp into a jar
file, but is also responsible for creating the HTML documentation in
the form of javadocs.

These are the meaningful targets for this build file:

 - package [default] -> creates ./build/opennlp-common.jar
 - compile -> compiles the source code
 - javadoc -> generates the API documentation in ./build/javadocs
 - clean -> restores the distribution to its original and clean state

For example, to build the Java API documentation, type

build.sh javadoc
(Unix)

To learn the details of what each target does, read the build.xml file.
It is quite understandable.

Downloading Models
==================
English models have been trained for each of the tools and are required
unless one wishes to create their own models from their own annotated
data.  These models can be downloaded by check out the "models" module
from the "/cvsroot/opennlp" repository on sourceforge.  The models are
large (especially the ones for the parser).  You may want to just fetch
specific ones.  Models for the corresponding components can be found in
the following directories:

chunker		- English-Penn-Treebank-style phrase chunker models.
namefind	- MUC-style named entity finder models.
parser		- English-Penn-Treebank-style parser models.
postag		- English-Penn-Treebank-style part-of-speech tagger.
sentdetect	- English sentence detector.
tokenize	- English-Penn-Treebank-style tokenizer.

Running the Tools
=================
To run any of these tools you need to have models.  Make sure you
look at the previous step before you try this.  Each of these classes
contains a main which will annotate text from standard in.  Some of
them require processing by the previous component.  Most of these take a
single argument which is the location of the model for this component.
The exceptions are the parser which requires a  model directory, and
the namefinder which takes a list of models.

sentence detector:	opennlp.tools.sentdetect.EnglishSentenceDetectorME
tokenizer: 		opennlp.tools.tokenize.EnglishTokenizerME
pos-tagger:		opennlp.tools.postag.EnglishPOSTaggerME
chunker:		opennlp.tools.chunker.EnglishTreebankChunker
name finder:		opennlp.tools.namefinder.EnglishNameFinder
parser:			opennlp.tools.parser.EnglishTreebankParser

Examples: This is not a recomendation that you run the tools this way.  It's
in fact very inefficient.  However, this should give you an idea of what the
tools can do and the kind of input they assume.  Developers should know to 
look at the main's of these classes to see how to set up a particular 
component for use.

Phrase Chunking:
java opennlp.tools.sentdetect.EnglishSentenceDetectorME 
  opennlp.models/sentdetect/EnglishSD.bin.gz < text | 
java opennlp.tools.tokenize.EnglishTokenizerME 
  opennlp.models/tokenize/EnglishTok.bin.gz | 
java opennlp.tools.postag.EnglishPOSTaggerME 
  opennlp.models/postag/EnglishPOS.bin.gz | 
java opennlp.tools.chunker.EnglishTreebankChunker 
  opennlp.models/chunker/EnglishChunk.bin.gz

Parsing:
java opennlp.tools.sentdetect.EnglishSentenceDetectorME 
  opennlp.models/sentdetect/EnglishSD.bin.gz < text | 
java opennlp.tools.tokenize.EnglishTokenizerME 
   opennlp.models/tokenize/EnglishTok.bin.gz | 
java -mx300M opennlp.tools.parser.EnglishTreebankParser
  opennlp.models/parser
    
Name Finding:
java opennlp.tools.sentdetect.EnglishSentenceDetectorME 
  opennlp.models/sentdetect/EnglishSD.bin.gz < text |
java -mx500M opennlp.tools.namefind.EnglishNameFinder 
  opennlp.models/namefind/*.bin.gz

Training the Tools
==================
The main of the following classes can be used to train new models.
Look at the usage messages for these classes you are interested in
training new models.

sentence detector:	opennlp.tools.sentdetect.SentenceDetectorME
tokenizer: 		opennlp.tools.tokenize.TokenizerME
pos-tagger: 		opennlp.tools.postag.POSTaggerME
chunker: 		opennlp.tools.chunker.ChunkerME
name finder: 		opennlp.tools.namefind.NameFinderME
parser: 		opennlp.tools.parser.ParserME

Bug Reports
===========

Please report bugs at the bug section of the OpenNLP sourceforge site:

http://sourceforge.net/tracker/?atid=103368&group_id=3368&func=browse

Note: Incorrect automatic-annotation on a specific piece of text does
not constitute a bug.  The best way to address such errors is to provide
annotated data on which the automatic-annotator/tagger can be trained
so that it might learn to not make these mistakes in the future.

Special Note
============

This README and the directory structure and the build system for this
project were taken directly from the JDOM project. Many thanks to
Jason Hunter and Brett McLaughlin for creating a very elegant way of
working with XML in Java.  See www.jdom.org for more details.
